'use client';

import { useState, useCallback, useRef } from 'react';
import {
  ChatMessage,
  ChatUsage,
  LayersMetadata,
  RateLimitInfo,
  chatStream,
  chat,
  StreamChunk,
  MessageContent,
  ImageContent,
  TextContent,
  Tool,
  ToolCall,
  ChatRequest,
  ResponseFormat,
  GeneratedImage,
  WebSearchCitation,
} from '@/lib/layers-client';
import type { AttachedImage } from '@/components/prompt-editor';
import type { CapabilitySettings, ToolDefinition } from '@/components/capabilities-panel';

export interface ChatSettings {
  model: string;
  maxTokens: number;
  temperature: number;
  systemPrompt: string;
  stream: boolean;
}

// Convert our tool definitions to OpenAI format
function convertToolsToOpenAIFormat(tools: ToolDefinition[]): Tool[] {
  return tools.map((tool) => ({
    type: 'function' as const,
    function: {
      name: tool.name,
      description: tool.description,
      parameters: JSON.parse(tool.parameters || '{}'),
    },
  }));
}

// Build tool_choice parameter
function buildToolChoice(toolChoice: string, tools: ToolDefinition[]) {
  if (toolChoice === 'auto' || toolChoice === 'none' || toolChoice === 'required') {
    return toolChoice;
  }
  // Specific function name
  const matchingTool = tools.find(t => t.name === toolChoice);
  if (matchingTool) {
    return { type: 'function' as const, function: { name: toolChoice } };
  }
  return 'auto';
}

// Build response format for JSON/structured output
function buildResponseFormat(jsonMode: boolean, jsonSchema: string): ResponseFormat | undefined {
  if (!jsonMode) return undefined;

  if (jsonSchema.trim()) {
    try {
      const schema = JSON.parse(jsonSchema);
      return {
        type: 'json_schema',
        json_schema: {
          name: 'response',
          schema,
          strict: true,
        },
      };
    } catch {
      // Invalid schema, fall back to json_object mode
      return { type: 'json_object' };
    }
  }

  return { type: 'json_object' };
}

export interface Message extends ChatMessage {
  id: string;
  isStreaming?: boolean;
  usage?: ChatUsage;
  layers?: LayersMetadata;
  error?: string;
  timestamp: number;
  images?: AttachedImage[]; // Original images for display in UI
  toolCalls?: ToolCall[]; // Tool/function calls from assistant
  thinking?: string; // Extended thinking content (from Anthropic)
  generatedImages?: GeneratedImage[]; // Images generated by DALL-E or similar
  citations?: WebSearchCitation[]; // Web search citations (from Perplexity)
}

export interface UseLayersChatReturn {
  messages: Message[];
  isLoading: boolean;
  error: string | null;
  rateLimitInfo: RateLimitInfo | null;
  totalUsage: {
    promptTokens: number;
    completionTokens: number;
    totalCredits: number;
  };
  sendMessage: (content: string, images?: AttachedImage[]) => Promise<void>;
  clearMessages: () => void;
  stopGeneration: () => void;
  regenerateLast: () => Promise<void>;
}

function generateId(): string {
  return `msg_${Date.now()}_${Math.random().toString(36).slice(2, 9)}`;
}

export function useLayersChat(
  settings: ChatSettings,
  capabilitySettings?: CapabilitySettings
): UseLayersChatReturn {
  const [messages, setMessages] = useState<Message[]>([]);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [rateLimitInfo, setRateLimitInfo] = useState<RateLimitInfo | null>(null);
  const [totalUsage, setTotalUsage] = useState({
    promptTokens: 0,
    completionTokens: 0,
    totalCredits: 0,
  });

  const abortControllerRef = useRef<AbortController | null>(null);

  // Convert attached images to API format
  const buildImageContent = useCallback((images: AttachedImage[]): ImageContent[] => {
    return images.map(img => ({
      type: 'image_url' as const,
      image_url: {
        url: img.dataUrl,
        detail: 'auto' as const,
      },
    }));
  }, []);

  // Build multi-part content (text + images)
  const buildMultipartContent = useCallback(
    (text: string, images?: AttachedImage[]): MessageContent => {
      if (!images || images.length === 0) {
        return text;
      }

      const content: (TextContent | ImageContent)[] = [];

      // Add images first
      content.push(...buildImageContent(images));

      // Add text if present
      if (text.trim()) {
        content.push({
          type: 'text',
          text: text.trim(),
        });
      }

      return content;
    },
    [buildImageContent]
  );

  const buildMessagesPayload = useCallback(
    (currentMessages: Message[], newContent?: string, newImages?: AttachedImage[]): ChatMessage[] => {
      const payload: ChatMessage[] = [];

      // Add system prompt if set
      if (settings.systemPrompt.trim()) {
        payload.push({
          role: 'system',
          content: settings.systemPrompt,
        });
      }

      // Add conversation history
      for (const msg of currentMessages) {
        if (msg.role !== 'system') {
          // If message has images, rebuild multipart content
          if (msg.images && msg.images.length > 0) {
            const textContent = typeof msg.content === 'string'
              ? msg.content
              : msg.content.find((c): c is TextContent => c.type === 'text')?.text || '';
            payload.push({
              role: msg.role,
              content: buildMultipartContent(textContent, msg.images),
            });
          } else {
            payload.push({
              role: msg.role,
              content: msg.content,
            });
          }
        }
      }

      // Add new user message if provided
      if (newContent || (newImages && newImages.length > 0)) {
        payload.push({
          role: 'user',
          content: buildMultipartContent(newContent || '', newImages),
        });
      }

      return payload;
    },
    [settings.systemPrompt, buildMultipartContent]
  );

  const sendMessage = useCallback(
    async (content: string, images?: AttachedImage[]) => {
      if ((!content.trim() && (!images || images.length === 0)) || isLoading) return;

      setError(null);
      setIsLoading(true);

      // Create new abort controller for this request
      abortControllerRef.current = new AbortController();

      // Build user message content
      const messageContent = buildMultipartContent(content.trim(), images);

      // Add user message
      const userMessage: Message = {
        id: generateId(),
        role: 'user',
        content: messageContent,
        timestamp: Date.now(),
        images: images, // Store original images for UI display
      };

      // Add placeholder assistant message for streaming
      const assistantMessage: Message = {
        id: generateId(),
        role: 'assistant',
        content: '',
        isStreaming: true,
        timestamp: Date.now(),
      };

      setMessages((prev) => [...prev, userMessage, assistantMessage]);

      try {
        const messagesPayload = buildMessagesPayload(messages, content, images);

        if (settings.stream) {
          // Build request with capability settings
          const request: ChatRequest = {
            model: settings.model,
            messages: messagesPayload,
            max_tokens: settings.maxTokens,
            temperature: settings.temperature,
            stream: true,
          };

          // Add capability settings if enabled
          if (capabilitySettings) {
            // Tools / Function calling
            if (capabilitySettings.toolsEnabled && capabilitySettings.tools.length > 0) {
              const validTools = capabilitySettings.tools.filter(t => t.name.trim());
              if (validTools.length > 0) {
                request.tools = convertToolsToOpenAIFormat(validTools);
                request.tool_choice = buildToolChoice(capabilitySettings.toolChoice, validTools);
              }
            }

            // JSON mode / Structured output
            if (capabilitySettings.jsonMode) {
              request.response_format = buildResponseFormat(true, capabilitySettings.jsonSchema);
            }

            // Extended thinking (Anthropic models)
            if (capabilitySettings.thinkingEnabled && capabilitySettings.thinkingBudget > 0) {
              request.thinking = {
                type: 'enabled',
                budget_tokens: capabilitySettings.thinkingBudget,
              };
            }

            // Web search
            if (capabilitySettings.webSearchEnabled) {
              request.web_search = true;
              if (capabilitySettings.searchDomains.length > 0) {
                request.search_domains = capabilitySettings.searchDomains;
              }
            }

            // Prompt caching
            if (capabilitySettings.cacheEnabled) {
              request.cache = true;
            }
          }

          // Streaming mode
          const { stream, rateLimitInfo: rateInfo } = await chatStream(request);

          setRateLimitInfo(rateInfo);

          let fullContent = '';
          let finalUsage: ChatUsage | undefined;
          let finalLayers: LayersMetadata | undefined;
          // Track tool calls being built from streaming chunks
          const toolCallsInProgress: Map<number, ToolCall> = new Map();

          for await (const chunk of stream) {
            // Check for abort
            if (abortControllerRef.current?.signal.aborted) {
              break;
            }

            // Extract content from chunk
            const delta = chunk.choices[0]?.delta;
            if (delta?.content) {
              fullContent += delta.content;

              // Update message with accumulated content
              setMessages((prev) =>
                prev.map((msg) =>
                  msg.id === assistantMessage.id
                    ? { ...msg, content: fullContent }
                    : msg
                )
              );
            }

            // Handle tool calls in streaming
            if (delta?.tool_calls) {
              for (const toolCallDelta of delta.tool_calls) {
                const existingCall = toolCallsInProgress.get(toolCallDelta.index);
                if (existingCall) {
                  // Append to existing tool call
                  if (toolCallDelta.function?.arguments) {
                    existingCall.function.arguments += toolCallDelta.function.arguments;
                  }
                } else if (toolCallDelta.id) {
                  // New tool call
                  toolCallsInProgress.set(toolCallDelta.index, {
                    id: toolCallDelta.id,
                    type: 'function',
                    function: {
                      name: toolCallDelta.function?.name || '',
                      arguments: toolCallDelta.function?.arguments || '',
                    },
                  });
                }
              }

              // Update message with tool calls
              const toolCalls = Array.from(toolCallsInProgress.values());
              setMessages((prev) =>
                prev.map((msg) =>
                  msg.id === assistantMessage.id
                    ? { ...msg, toolCalls }
                    : msg
                )
              );
            }

            // Capture usage and layers data from final chunk
            if (chunk.usage) {
              finalUsage = chunk.usage;
            }
            if (chunk.layers) {
              finalLayers = chunk.layers;
            }
          }

          // Finalize the message
          const finalToolCalls = toolCallsInProgress.size > 0
            ? Array.from(toolCallsInProgress.values())
            : undefined;

          setMessages((prev) =>
            prev.map((msg) =>
              msg.id === assistantMessage.id
                ? {
                    ...msg,
                    content: fullContent,
                    isStreaming: false,
                    usage: finalUsage,
                    layers: finalLayers,
                    toolCalls: finalToolCalls,
                  }
                : msg
            )
          );

          // Update total usage
          if (finalUsage && finalLayers) {
            setTotalUsage((prev) => ({
              promptTokens: prev.promptTokens + finalUsage!.prompt_tokens,
              completionTokens: prev.completionTokens + finalUsage!.completion_tokens,
              totalCredits: prev.totalCredits + finalLayers!.credits_used,
            }));
          }
        } else {
          // Build request with capability settings (same as streaming)
          const request: ChatRequest = {
            model: settings.model,
            messages: messagesPayload,
            max_tokens: settings.maxTokens,
            temperature: settings.temperature,
            stream: false,
          };

          // Add capability settings if enabled
          if (capabilitySettings) {
            if (capabilitySettings.toolsEnabled && capabilitySettings.tools.length > 0) {
              const validTools = capabilitySettings.tools.filter(t => t.name.trim());
              if (validTools.length > 0) {
                request.tools = convertToolsToOpenAIFormat(validTools);
                request.tool_choice = buildToolChoice(capabilitySettings.toolChoice, validTools);
              }
            }
            if (capabilitySettings.jsonMode) {
              request.response_format = buildResponseFormat(true, capabilitySettings.jsonSchema);
            }
            if (capabilitySettings.thinkingEnabled && capabilitySettings.thinkingBudget > 0) {
              request.thinking = {
                type: 'enabled',
                budget_tokens: capabilitySettings.thinkingBudget,
              };
            }
            if (capabilitySettings.webSearchEnabled) {
              request.web_search = true;
              if (capabilitySettings.searchDomains.length > 0) {
                request.search_domains = capabilitySettings.searchDomains;
              }
            }
            if (capabilitySettings.cacheEnabled) {
              request.cache = true;
            }
          }

          // Non-streaming mode
          const response = await chat(request);

          const assistantContent = response.choices[0]?.message?.content || '';
          const toolCalls = response.choices[0]?.message?.tool_calls;

          setMessages((prev) =>
            prev.map((msg) =>
              msg.id === assistantMessage.id
                ? {
                    ...msg,
                    content: assistantContent,
                    isStreaming: false,
                    usage: response.usage,
                    layers: response.layers,
                    toolCalls: toolCalls,
                  }
                : msg
            )
          );

          // Update total usage
          if (response.usage && response.layers) {
            setTotalUsage((prev) => ({
              promptTokens: prev.promptTokens + response.usage.prompt_tokens,
              completionTokens: prev.completionTokens + response.usage.completion_tokens,
              totalCredits: prev.totalCredits + response.layers!.credits_used,
            }));
          }
        }
      } catch (err) {
        const errorMessage = err instanceof Error ? err.message : 'An error occurred';
        setError(errorMessage);

        // Update assistant message with error
        setMessages((prev) =>
          prev.map((msg) =>
            msg.id === assistantMessage.id
              ? {
                  ...msg,
                  content: '',
                  isStreaming: false,
                  error: errorMessage,
                }
              : msg
          )
        );
      } finally {
        setIsLoading(false);
        abortControllerRef.current = null;
      }
    },
    [messages, settings, capabilitySettings, isLoading, buildMessagesPayload, buildMultipartContent]
  );

  const clearMessages = useCallback(() => {
    setMessages([]);
    setError(null);
    setRateLimitInfo(null);
    setTotalUsage({
      promptTokens: 0,
      completionTokens: 0,
      totalCredits: 0,
    });
  }, []);

  const stopGeneration = useCallback(() => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
      setIsLoading(false);

      // Mark any streaming messages as complete
      setMessages((prev) =>
        prev.map((msg) =>
          msg.isStreaming
            ? { ...msg, isStreaming: false }
            : msg
        )
      );
    }
  }, []);

  const regenerateLast = useCallback(async () => {
    // Find the last user message
    const lastUserIndex = messages.findLastIndex((m) => m.role === 'user');
    if (lastUserIndex === -1) return;

    const lastUserMessage = messages[lastUserIndex];

    // Extract text content from the message
    const textContent = typeof lastUserMessage.content === 'string'
      ? lastUserMessage.content
      : lastUserMessage.content.find((c): c is TextContent => c.type === 'text')?.text || '';

    // Remove all messages after (and including) the last user message
    setMessages((prev) => prev.slice(0, lastUserIndex));

    // Resend the message with images if they were attached
    await sendMessage(textContent, lastUserMessage.images);
  }, [messages, sendMessage]);

  return {
    messages,
    isLoading,
    error,
    rateLimitInfo,
    totalUsage,
    sendMessage,
    clearMessages,
    stopGeneration,
    regenerateLast,
  };
}
