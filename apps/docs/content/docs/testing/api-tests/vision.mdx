---
title: Vision Tests (API)
description: 2 tests for image understanding via the Layers API
---

# Vision Tests (API)

Vision tests verify that the Layers API correctly processes multimodal requests with images.

## Test Summary

| Test | Model | Description |
|------|-------|-------------|
| Claude Vision | claude-sonnet-4.5 | Describe image content |
| GPT-4o Vision | gpt-4o | Describe image content |

## Running Tests

```bash
cd packages/@layers/models
LAYERS_API_URL=https://web-nine-sage-13.vercel.app \
LAYERS_API_KEY=lyr_live_xxx \
bun test layers-api -t "Vision"
```

## Test Implementation

### Claude Vision Test

```typescript
it('should process images with Claude via API', async () => {
  const response = await fetch(`${LAYERS_API_URL}/api/v1/chat`, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${LAYERS_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'anthropic/claude-sonnet-4.5',
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image_url',
              image_url: {
                url: 'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8z8BQDwAEhQGAhKmMIQAAAABJRU5ErkJggg==',
              },
            },
            {
              type: 'text',
              text: 'What color is this image? Reply with just the color name.',
            },
          ],
        },
      ],
      max_tokens: 20,
    }),
  });

  expect(response.status).toBe(200);
  const data = await response.json();
  expect(data.choices[0].message.content.toLowerCase()).toContain('red');
});
```

### GPT-4o Vision Test

```typescript
it('should process images with GPT-4o via API', async () => {
  const response = await fetch(`${LAYERS_API_URL}/api/v1/chat`, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${LAYERS_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'openai/gpt-4o',
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image_url',
              image_url: {
                url: 'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8z8BQDwAEhQGAhKmMIQAAAABJRU5ErkJggg==',
              },
            },
            {
              type: 'text',
              text: 'What color is this image?',
            },
          ],
        },
      ],
      max_tokens: 20,
    }),
  });

  expect(response.status).toBe(200);
  const data = await response.json();
  expect(data.choices[0].message.content.toLowerCase()).toContain('red');
});
```

## Request Format (OpenAI Compatible)

```json
{
  "model": "anthropic/claude-sonnet-4.5",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "type": "image_url",
          "image_url": {
            "url": "data:image/png;base64,..."
          }
        },
        {
          "type": "text",
          "text": "Describe this image."
        }
      ]
    }
  ],
  "max_tokens": 300
}
```

## Image Formats

| Format | Example |
|--------|---------|
| Base64 Data URL | `data:image/png;base64,iVBOR...` |
| Base64 JPEG | `data:image/jpeg;base64,/9j/4AAQ...` |
| HTTP URL | `https://example.com/image.png` |

## Supported Models

| Model | Vision Support |
|-------|----------------|
| anthropic/claude-sonnet-4.5 | Yes |
| anthropic/claude-opus-4.5 | Yes |
| anthropic/claude-haiku-4.5 | Yes |
| openai/gpt-4o | Yes |
| openai/gpt-4o-mini | Yes |
| google/gemini-2.5-flash | Yes |
| perplexity/sonar | No |
| morph/morph-v3-fast | No |

## Usage Example

```typescript
// Using base64 image
const imageData = fs.readFileSync('photo.jpg');
const base64 = imageData.toString('base64');

const response = await fetch('https://api.layers.dev/v1/chat', {
  method: 'POST',
  headers: {
    'Authorization': 'Bearer lyr_live_xxx',
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    model: 'anthropic/claude-sonnet-4.5',
    messages: [
      {
        role: 'user',
        content: [
          {
            type: 'image_url',
            image_url: {
              url: `data:image/jpeg;base64,${base64}`,
            },
          },
          {
            type: 'text',
            text: 'What objects are in this image?',
          },
        ],
      },
    ],
    max_tokens: 500,
  }),
});
```

## Multiple Images

```json
{
  "model": "anthropic/claude-sonnet-4.5",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "type": "image_url",
          "image_url": { "url": "data:image/png;base64,..." }
        },
        {
          "type": "image_url",
          "image_url": { "url": "data:image/png;base64,..." }
        },
        {
          "type": "text",
          "text": "Compare these two images."
        }
      ]
    }
  ]
}
```

## Best Practices

1. **Optimize image size** - Resize large images before sending
2. **Use appropriate models** - Vision models cost more
3. **Be specific** - Ask targeted questions for better results
4. **Handle errors** - Some images may fail to process
