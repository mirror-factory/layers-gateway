---
title: API Reference
description: Complete documentation for the Layers API v1 endpoints
---

# API Reference

The Layers API provides a unified interface to access AI models from multiple providers using a single API key and credit balance.

## Base URL

```
https://api.layers.dev/api/v1
```

> **Note:** During beta, use `https://web-nine-sage-13.vercel.app/api/v1`

## Authentication

All API requests require authentication using a Layers API key.

```bash
Authorization: Bearer lyr_live_xxxxx
```

API keys are prefixed with:
- `lyr_live_` - Production keys (deduct credits)
- `lyr_test_` - Test keys (for development, limited usage)

See the [Authentication Guide](/docs/authentication) for details.

---

## Chat Completions

Create a chat completion with any supported language model.

### Endpoint

```
POST /api/v1/chat
```

### Request Headers

| Header | Required | Description |
|--------|----------|-------------|
| `Authorization` | Yes | `Bearer lyr_live_xxxxx` |
| `Content-Type` | Yes | `application/json` |

### Request Body

```typescript
{
  model: string;        // Required: Model ID (e.g., "anthropic/claude-sonnet-4.5")
  messages: Message[];  // Required: Array of messages
  max_tokens?: number;  // Optional: Maximum output tokens (default: 1024)
  temperature?: number; // Optional: Sampling temperature (0-2)
  stream?: boolean;     // Optional: Enable streaming (not yet implemented)
}

interface Message {
  role: "system" | "user" | "assistant";
  content: string;
}
```

### Response (Success - 200)

```typescript
{
  id: string;           // Unique request ID
  object: "chat.completion";
  created: number;      // Unix timestamp
  model: string;        // Model used
  choices: [{
    index: 0;
    message: {
      role: "assistant";
      content: string;  // The AI response
    };
    finish_reason: "stop";
  }];
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
  layers: {             // Layers-specific metadata
    credits_used: number;
    latency_ms: number;
  };
}
```

### Example Request

#### cURL

```bash
curl -X POST https://web-nine-sage-13.vercel.app/api/v1/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer lyr_live_xxxxx" \
  -d '{
    "model": "anthropic/claude-sonnet-4.5",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "What is the capital of France?"}
    ],
    "max_tokens": 256
  }'
```

#### TypeScript

```typescript
const response = await fetch('https://web-nine-sage-13.vercel.app/api/v1/chat', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${process.env.LAYERS_API_KEY}`,
  },
  body: JSON.stringify({
    model: 'anthropic/claude-sonnet-4.5',
    messages: [
      { role: 'system', content: 'You are a helpful assistant.' },
      { role: 'user', content: 'What is the capital of France?' }
    ],
    max_tokens: 256,
  }),
});

const data = await response.json();
console.log(data.choices[0].message.content);
// "The capital of France is Paris."
```

#### Python

```python
import requests
import os

response = requests.post(
    'https://web-nine-sage-13.vercel.app/api/v1/chat',
    headers={
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {os.environ["LAYERS_API_KEY"]}'
    },
    json={
        'model': 'anthropic/claude-sonnet-4.5',
        'messages': [
            {'role': 'system', 'content': 'You are a helpful assistant.'},
            {'role': 'user', 'content': 'What is the capital of France?'}
        ],
        'max_tokens': 256
    }
)

data = response.json()
print(data['choices'][0]['message']['content'])
# "The capital of France is Paris."
```

---

## Health Check

Check API status and version.

### Endpoint

```
GET /api/v1/chat
```

### Response

```json
{
  "status": "ok",
  "version": "v1",
  "endpoints": {
    "chat": "POST /api/v1/chat"
  },
  "docs": "https://web-nine-sage-13.vercel.app/docs",
  "timestamp": "2026-01-16T12:00:00.000Z"
}
```

---

## Error Responses

All errors follow this format:

```typescript
{
  error: string;       // Error message
  details?: string;    // Additional details (for debugging)
}
```

### Error Codes

| Code | Error | Description |
|------|-------|-------------|
| `400` | Bad Request | Invalid request body or missing required fields |
| `401` | Unauthorized | Missing, invalid, or expired API key |
| `402` | Payment Required | Insufficient credits |
| `429` | Too Many Requests | Rate limit exceeded |
| `500` | Internal Server Error | Unexpected error |
| `501` | Not Implemented | Feature not yet available (e.g., streaming) |

### Error Examples

**Invalid API Key (401)**
```json
{
  "error": "Invalid API key format. Keys must start with lyr_live_"
}
```

**Insufficient Credits (402)**
```json
{
  "error": "Insufficient credits",
  "balance": 5.2,
  "estimated_required": 12.8
}
```

**Rate Limit Exceeded (429)**
```json
{
  "error": "Rate limit exceeded",
  "limit": 10,
  "reset_at": "2026-01-16T12:01:00.000Z"
}
```

---

## Rate Limits

Rate limits are based on your subscription tier:

| Tier | Requests/Minute | Headers |
|------|-----------------|---------|
| **Free** | 10 | `X-RateLimit-Limit: 10` |
| **Starter** | 60 | `X-RateLimit-Limit: 60` |
| **Pro** | 300 | `X-RateLimit-Limit: 300` |
| **Team** | 1,000 | `X-RateLimit-Limit: 1000` |

### Rate Limit Headers

Every response includes these headers:

| Header | Description |
|--------|-------------|
| `X-RateLimit-Limit` | Maximum requests per minute |
| `X-RateLimit-Remaining` | Remaining requests in window |
| `X-RateLimit-Reset` | Unix timestamp when window resets |

---

## Supported Models

### Language Models

| Provider | Models | Capabilities |
|----------|--------|--------------|
| **Anthropic** | claude-haiku-4.5, claude-sonnet-4.5, claude-opus-4.5 | Text, Vision, Tools, Thinking |
| **OpenAI** | gpt-4o, gpt-4o-mini, gpt-5-chat, gpt-5-codex, gpt-5.1-* | Text, Vision, Tools, Codex |
| **Google** | gemini-2.5-flash, gemini-2.5-pro, gemini-3-flash, gemini-3-pro-preview | Text, Vision, Multimodal |
| **Perplexity** | sonar, sonar-pro, sonar-reasoning-pro | Web Search, Reasoning |
| **Morph** | morph-v3-fast, morph-v3-large | Fast text editing |

**Model ID Format:** `provider/model-name`

**Example:** `anthropic/claude-sonnet-4.5`, `openai/gpt-4o`, `google/gemini-2.5-flash`

See [Model Selection Guide](/docs/models) for detailed capabilities and pricing.

---

## OpenAI Compatibility

The Layers API is designed to be compatible with the OpenAI API format. You can use existing OpenAI client libraries by:

1. Changing the base URL to Layers
2. Using your Layers API key
3. Using `provider/model` format for model names

```typescript
import OpenAI from 'openai';

const client = new OpenAI({
  baseURL: 'https://web-nine-sage-13.vercel.app/api/v1',
  apiKey: process.env.LAYERS_API_KEY,
});

const completion = await client.chat.completions.create({
  model: 'anthropic/claude-sonnet-4.5',  // Any Layers model
  messages: [{ role: 'user', content: 'Hello!' }],
});
```

---

## Next Steps

- [Getting Started](/docs/getting-started) - Quick setup guide
- [Authentication](/docs/authentication) - API key management
- [Credit System](/docs/credits) - Pricing and usage
- [Playground](/docs/playground) - Test models interactively
