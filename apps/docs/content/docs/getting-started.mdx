---
title: Getting Started
description: Start using Layers in under 5 minutes
---

# Getting Started

Get up and running with Layers in under 5 minutes.

## What is Layers?

Layers is a unified AI API that gives you access to 23+ language models and 11 image generation models from multiple providers through a single API key and credit balance.

**Why use Layers?**

| Challenge | Layers Solution |
|-----------|-----------------|
| Managing multiple API keys | One API key for all providers |
| Different billing accounts | Single credit balance |
| Inconsistent APIs | OpenAI-compatible format |
| Rate limit management | Unified rate limiting by tier |
| Usage tracking | Built-in analytics |

## Quick Start

### 1. Get Your API Key

> **Beta:** API keys are currently invite-only. [Join the waitlist](#) or use the demo playground.

Once you have access, your API key will look like:

```
lyr_live_sk_1234567890abcdef...
```

### 2. Make Your First Request

#### cURL

```bash
curl -X POST https://preview.hustletogether.com/api/v1/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "anthropic/claude-sonnet-4.5",
    "messages": [
      {"role": "user", "content": "Say hello!"}
    ]
  }'
```

#### TypeScript

```typescript
const response = await fetch('https://preview.hustletogether.com/api/v1/chat', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer YOUR_API_KEY',
  },
  body: JSON.stringify({
    model: 'anthropic/claude-sonnet-4.5',
    messages: [{ role: 'user', content: 'Say hello!' }],
  }),
});

const data = await response.json();
console.log(data.choices[0].message.content);
```

#### Python

```python
import requests

response = requests.post(
    'https://preview.hustletogether.com/api/v1/chat',
    headers={
        'Content-Type': 'application/json',
        'Authorization': 'Bearer YOUR_API_KEY'
    },
    json={
        'model': 'anthropic/claude-sonnet-4.5',
        'messages': [{'role': 'user', 'content': 'Say hello!'}]
    }
)

print(response.json()['choices'][0]['message']['content'])
```

### 3. Check the Response

A successful response looks like:

```json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "model": "anthropic/claude-sonnet-4.5",
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "Hello! How can I help you today?"
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 12,
    "completion_tokens": 8,
    "total_tokens": 20
  },
  "layers": {
    "credits_used": 0.05,
    "latency_ms": 342
  }
}
```

---

## Try Different Models

Just change the `model` parameter:

```bash
# Fast and cheap
"model": "openai/gpt-4o-mini"

# Balanced performance
"model": "anthropic/claude-sonnet-4.5"

# Best quality
"model": "anthropic/claude-opus-4.5"

# Web search included
"model": "perplexity/sonar-pro"
```

See [Model Selection Guide](/docs/models) for all 23 models.

---

## Use System Prompts

Add a system message to control behavior:

```json
{
  "model": "anthropic/claude-sonnet-4.5",
  "messages": [
    {"role": "system", "content": "You are a concise coding assistant. Give short, direct answers."},
    {"role": "user", "content": "How do I reverse a string in Python?"}
  ]
}
```

---

## Check Your Balance

Include rate limit headers in your requests to see usage:

```
X-RateLimit-Limit: 60
X-RateLimit-Remaining: 58
X-RateLimit-Reset: 1705402860
```

---

## Using the Vercel AI SDK

If you're building with Next.js, use the Vercel AI SDK with our gateway:

```bash
npm install ai
```

```typescript
import { generateText, createGateway } from 'ai';

const gateway = createGateway({
  apiKey: process.env.AI_GATEWAY_API_KEY,
});

const { text } = await generateText({
  model: gateway('anthropic/claude-sonnet-4.5'),
  prompt: 'Explain quantum computing in one sentence.',
});

console.log(text);
```

---

## SDK Packages

For advanced use cases, install our SDK packages:

```bash
npm install @layers/models @layers/credits
```

**@layers/models** - Model registry with pricing:

```typescript
import { getModel, getModelsByCapability } from '@layers/models';

const model = getModel('anthropic/claude-sonnet-4.5');
console.log(model.pricing); // { input: 3.00, output: 15.00 }
```

**@layers/credits** - Credit calculations:

```typescript
import { calculateCredits } from '@layers/credits';

const credits = calculateCredits('anthropic/claude-sonnet-4.5', 1000, 500);
console.log(`This request costs ${credits} credits`);
```

---

## Subscription Tiers

| Tier | Price | Credits | Rate Limit |
|------|-------|---------|------------|
| **Free** | $0 | 50/month | 10 req/min |
| **Starter** | $20/mo | 500/month | 60 req/min |
| **Pro** | $100/mo | 3,000/month | 300 req/min |
| **Team** | $200/mo | 7,500/month | 1,000 req/min |

See [Credit System](/docs/credits) for detailed pricing.

---

## Next Steps

- [API Reference](/docs/api/reference) - Full endpoint documentation
- [Model Selection](/docs/models) - Choose the right model
- [Playground](/docs/playground) - Test models interactively
- [Credit System](/docs/credits) - Understand pricing

---

## Need Help?

- **Playground:** Test models without code at [Playground](/docs/playground)
- **Examples:** See code examples in [API Reference](/docs/api/reference)
- **Support:** Contact support@layers.dev
