---
title: API Reference
description: Complete documentation for the Layers API v1 endpoints
---

# API Reference

The Layers API provides a unified interface to access AI models from multiple providers using a single API key and credit balance.

## Base URL

```
https://api.layers.dev/api/v1
```

> **Note:** During beta, use `https://web-nine-sage-13.vercel.app/api/v1`

## Authentication

All API requests require authentication using a Layers API key.

```bash
Authorization: Bearer lyr_live_xxxxx
```

API keys are prefixed with:
- `lyr_live_` - Production keys (deduct credits)
- `lyr_test_` - Test keys (for development, limited usage)

See the [Authentication Guide](/docs/authentication) for details.

---

## Chat Completions

Create a chat completion with any supported language model.

### Endpoint

```
POST /api/v1/chat
```

### Request Headers

| Header | Required | Description |
|--------|----------|-------------|
| `Authorization` | Yes | `Bearer lyr_live_xxxxx` |
| `Content-Type` | Yes | `application/json` |

### Request Body

```typescript
{
  // Required
  model: string;           // Model ID (e.g., "anthropic/claude-sonnet-4.5")
  messages: Message[];     // Array of messages

  // Basic Options
  max_tokens?: number;     // Maximum output tokens (default: 1024)
  temperature?: number;    // Sampling temperature (0-2)
  stream?: boolean;        // Enable SSE streaming

  // Tools / Function Calling
  tools?: Tool[];          // Tool definitions
  tool_choice?: "auto" | "none" | "required" | { type: "function", function: { name: string } };

  // Structured Output
  response_format?: { type: "json_object" | "text" };

  // Extended Thinking (Anthropic models)
  thinking?: {
    type: "enabled";
    budget_tokens: number; // Max tokens for reasoning
  };

  // Web Search (Perplexity models)
  web_search?: boolean;
  search_domains?: string[];

  // Prompt Caching
  cache?: boolean;
}

interface Message {
  role: "system" | "user" | "assistant";
  content: string | ContentPart[];  // String or multimodal array
}

// For vision/multimodal
interface ContentPart {
  type: "text" | "image_url";
  text?: string;
  image_url?: { url: string; detail?: "low" | "high" | "auto" };
}

// For function calling
interface Tool {
  type: "function";
  function: {
    name: string;
    description: string;
    parameters?: object;  // JSON Schema
  };
}
```

### Response (Success - 200)

```typescript
{
  id: string;           // Unique request ID
  object: "chat.completion";
  created: number;      // Unix timestamp
  model: string;        // Model used
  choices: [{
    index: 0;
    message: {
      role: "assistant";
      content: string | null;  // The AI response (null if tool_calls)
      tool_calls?: [{          // Function calls (if tools used)
        id: string;
        type: "function";
        function: {
          name: string;
          arguments: string;   // JSON string
        };
      }];
    };
    finish_reason: "stop" | "tool_calls";
  }];
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
  layers: {             // Layers-specific metadata
    credits_used: number;
    latency_ms: number;
    reasoning?: object; // Extended thinking output (if enabled)
  };
}
```

### Streaming Response

When `stream: true`, the response is Server-Sent Events (SSE) format:

```
data: {"id":"...","object":"chat.completion.chunk","choices":[{"delta":{"content":"Hello"}}]}
data: {"id":"...","object":"chat.completion.chunk","choices":[{"delta":{"content":" there"}}]}
data: {"id":"...","object":"chat.completion.chunk","choices":[{"delta":{},"finish_reason":"stop"}]}
data: [DONE]
```

### Example Request

#### cURL

```bash
curl -X POST https://web-nine-sage-13.vercel.app/api/v1/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer lyr_live_xxxxx" \
  -d '{
    "model": "anthropic/claude-sonnet-4.5",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "What is the capital of France?"}
    ],
    "max_tokens": 256
  }'
```

#### TypeScript

```typescript
const response = await fetch('https://web-nine-sage-13.vercel.app/api/v1/chat', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${process.env.LAYERS_API_KEY}`,
  },
  body: JSON.stringify({
    model: 'anthropic/claude-sonnet-4.5',
    messages: [
      { role: 'system', content: 'You are a helpful assistant.' },
      { role: 'user', content: 'What is the capital of France?' }
    ],
    max_tokens: 256,
  }),
});

const data = await response.json();
console.log(data.choices[0].message.content);
// "The capital of France is Paris."
```

#### Python

```python
import requests
import os

response = requests.post(
    'https://web-nine-sage-13.vercel.app/api/v1/chat',
    headers={
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {os.environ["LAYERS_API_KEY"]}'
    },
    json={
        'model': 'anthropic/claude-sonnet-4.5',
        'messages': [
            {'role': 'system', 'content': 'You are a helpful assistant.'},
            {'role': 'user', 'content': 'What is the capital of France?'}
        ],
        'max_tokens': 256
    }
)

data = response.json()
print(data['choices'][0]['message']['content'])
# "The capital of France is Paris."
```

---

## Health Check

Check API status and version.

### Endpoint

```
GET /api/v1/chat
```

### Response

```json
{
  "status": "ok",
  "version": "v1",
  "endpoints": {
    "chat": "POST /api/v1/chat"
  },
  "docs": "https://web-nine-sage-13.vercel.app/docs",
  "timestamp": "2026-01-16T12:00:00.000Z"
}
```

---

## Error Responses

All errors follow this format:

```typescript
{
  error: string;       // Error message
  details?: string;    // Additional details (for debugging)
}
```

### Error Codes

| Code | Error | Description |
|------|-------|-------------|
| `400` | Bad Request | Invalid request body or missing required fields |
| `401` | Unauthorized | Missing, invalid, or expired API key |
| `402` | Payment Required | Insufficient credits |
| `429` | Too Many Requests | Rate limit exceeded |
| `500` | Internal Server Error | Unexpected error |
| `502` | Bad Gateway | Error communicating with AI provider |

### Error Examples

**Invalid API Key (401)**
```json
{
  "error": "Invalid API key format. Keys must start with lyr_live_"
}
```

**Insufficient Credits (402)**
```json
{
  "error": "Insufficient credits",
  "balance": 5.2,
  "estimated_required": 12.8
}
```

**Rate Limit Exceeded (429)**
```json
{
  "error": "Rate limit exceeded",
  "limit": 10,
  "reset_at": "2026-01-16T12:01:00.000Z"
}
```

---

## Rate Limits

Rate limits are based on your subscription tier:

| Tier | Requests/Minute | Headers |
|------|-----------------|---------|
| **Free** | 10 | `X-RateLimit-Limit: 10` |
| **Starter** | 60 | `X-RateLimit-Limit: 60` |
| **Pro** | 300 | `X-RateLimit-Limit: 300` |
| **Team** | 1,000 | `X-RateLimit-Limit: 1000` |

### Rate Limit Headers

Every response includes these headers:

| Header | Description |
|--------|-------------|
| `X-RateLimit-Limit` | Maximum requests per minute |
| `X-RateLimit-Remaining` | Remaining requests in window |
| `X-RateLimit-Reset` | Unix timestamp when window resets |

---

## Supported Models

### Language Models

| Provider | Models | Capabilities |
|----------|--------|--------------|
| **Anthropic** | claude-haiku-4.5, claude-sonnet-4.5, claude-opus-4.5 | Text, Vision, Tools, Thinking |
| **OpenAI** | gpt-4o, gpt-4o-mini, gpt-5-chat, gpt-5-codex, gpt-5.1-* | Text, Vision, Tools, Codex |
| **Google** | gemini-2.5-flash, gemini-2.5-pro, gemini-3-flash, gemini-3-pro-preview | Text, Vision, Multimodal |
| **Perplexity** | sonar, sonar-pro, sonar-reasoning-pro | Web Search, Reasoning |
| **Morph** | morph-v3-fast, morph-v3-large | Fast text editing |

**Model ID Format:** `provider/model-name`

**Example:** `anthropic/claude-sonnet-4.5`, `openai/gpt-4o`, `google/gemini-2.5-flash`

See [Model Selection Guide](/docs/models) for detailed capabilities and pricing.

---

## OpenAI Compatibility

The Layers API is designed to be compatible with the OpenAI API format. You can use existing OpenAI client libraries by:

1. Changing the base URL to Layers
2. Using your Layers API key
3. Using `provider/model` format for model names

```typescript
import OpenAI from 'openai';

const client = new OpenAI({
  baseURL: 'https://web-nine-sage-13.vercel.app/api/v1',
  apiKey: process.env.LAYERS_API_KEY,
});

const completion = await client.chat.completions.create({
  model: 'anthropic/claude-sonnet-4.5',  // Any Layers model
  messages: [{ role: 'user', content: 'Hello!' }],
});
```

---

## Advanced Features

### Vision / Multimodal

Send images with your messages for vision-capable models:

```typescript
const response = await fetch('/api/v1/chat', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${apiKey}`,
  },
  body: JSON.stringify({
    model: 'anthropic/claude-sonnet-4.5',
    messages: [{
      role: 'user',
      content: [
        { type: 'text', text: 'What is in this image?' },
        { type: 'image_url', image_url: { url: 'data:image/png;base64,...' } }
      ]
    }],
    max_tokens: 256,
  }),
});
```

### Function Calling / Tools

Define tools for the model to call:

```typescript
const response = await fetch('/api/v1/chat', {
  method: 'POST',
  headers: { /* ... */ },
  body: JSON.stringify({
    model: 'anthropic/claude-sonnet-4.5',
    messages: [{ role: 'user', content: 'What is 15 + 27?' }],
    tools: [{
      type: 'function',
      function: {
        name: 'calculator',
        description: 'Performs arithmetic operations',
        parameters: {
          type: 'object',
          properties: {
            a: { type: 'number' },
            b: { type: 'number' },
            operation: { type: 'string', enum: ['add', 'subtract', 'multiply', 'divide'] }
          },
          required: ['a', 'b', 'operation']
        }
      }
    }],
    tool_choice: 'auto',
  }),
});

// Response includes tool_calls:
// { message: { tool_calls: [{ function: { name: 'calculator', arguments: '{"a":15,"b":27,"operation":"add"}' } }] } }
```

### JSON Mode / Structured Output

Get structured JSON responses:

```typescript
const response = await fetch('/api/v1/chat', {
  method: 'POST',
  headers: { /* ... */ },
  body: JSON.stringify({
    model: 'anthropic/claude-sonnet-4.5',
    messages: [{ role: 'user', content: 'List 3 colors as JSON array' }],
    response_format: { type: 'json_object' },
  }),
});
// Response: { "colors": ["red", "blue", "green"] }
```

### Extended Thinking (Anthropic)

Enable chain-of-thought reasoning:

```typescript
const response = await fetch('/api/v1/chat', {
  method: 'POST',
  headers: { /* ... */ },
  body: JSON.stringify({
    model: 'anthropic/claude-sonnet-4.5',
    messages: [{ role: 'user', content: 'Solve this complex math problem...' }],
    thinking: {
      type: 'enabled',
      budget_tokens: 10000,
    },
  }),
});
// Response includes layers.reasoning with the model's thinking process
```

### Web Search (Perplexity)

Enable real-time web search:

```typescript
const response = await fetch('/api/v1/chat', {
  method: 'POST',
  headers: { /* ... */ },
  body: JSON.stringify({
    model: 'perplexity/sonar-pro',
    messages: [{ role: 'user', content: 'What are the latest AI news today?' }],
    web_search: true,
    search_domains: ['techcrunch.com', 'theverge.com'],  // Optional: limit domains
  }),
});
```

### Streaming

Get responses as they're generated:

```typescript
const response = await fetch('/api/v1/chat', {
  method: 'POST',
  headers: { /* ... */ },
  body: JSON.stringify({
    model: 'anthropic/claude-sonnet-4.5',
    messages: [{ role: 'user', content: 'Write a story...' }],
    stream: true,
  }),
});

const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;

  const chunk = decoder.decode(value);
  const lines = chunk.split('\n').filter(line => line.startsWith('data: '));

  for (const line of lines) {
    const data = line.slice(6);
    if (data === '[DONE]') continue;

    const parsed = JSON.parse(data);
    const content = parsed.choices[0]?.delta?.content;
    if (content) process.stdout.write(content);
  }
}
```

---

## Next Steps

- [Getting Started](/docs/getting-started) - Quick setup guide
- [Authentication](/docs/authentication) - API key management
- [Credit System](/docs/credits) - Pricing and usage
- [Dashboard](https://layers.hustletogether.com/dashboard) - Manage API keys
