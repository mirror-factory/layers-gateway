---
title: Rate Limits Tests
description: 3 tests for request throttling
---

# Rate Limits Tests

Rate limit tests verify that the Layers API correctly enforces request limits and returns appropriate headers and errors.

## Test Summary

| Test | Description |
|------|-------------|
| Rate Limit Headers | Headers included in responses |
| Within Limits | Requests succeed when under limit |
| Exceeded Limits | Returns 429 when limit exceeded |

## Running Tests

```bash
cd packages/@layers/models
LAYERS_API_URL=https://layers.hustletogether.com \
LAYERS_API_KEY=lyr_live_xxx \
bun test layers-api -t "Rate"
```

## Test Implementation

### Rate Limit Headers Test

```typescript
it('should include rate limit headers', async () => {
  const response = await fetch(`${LAYERS_API_URL}/api/v1/chat`, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${LAYERS_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'anthropic/claude-haiku-4.5',
      messages: [{ role: 'user', content: 'Say hi' }],
      max_tokens: 10,
    }),
  });

  expect(response.status).toBe(200);

  // Check rate limit headers
  expect(response.headers.get('X-RateLimit-Limit')).toBeTruthy();
  expect(response.headers.get('X-RateLimit-Remaining')).toBeTruthy();
  expect(response.headers.get('X-RateLimit-Reset')).toBeTruthy();
});
```

### Within Limits Test

```typescript
it('should allow requests within rate limit', async () => {
  // Make a few sequential requests
  for (let i = 0; i < 3; i++) {
    const response = await fetch(`${LAYERS_API_URL}/api/v1/chat`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${LAYERS_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'anthropic/claude-haiku-4.5',
        messages: [{ role: 'user', content: 'Say hi' }],
        max_tokens: 10,
      }),
    });

    expect(response.status).toBe(200);
  }
});
```

### Exceeded Limits Test

```typescript
it('should return 429 when rate limit exceeded', async () => {
  // This test uses a key with very low rate limit
  // or makes rapid requests to exceed limit

  const promises = Array.from({ length: 15 }, () =>
    fetch(`${LAYERS_API_URL}/api/v1/chat`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${LAYERS_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'anthropic/claude-haiku-4.5',
        messages: [{ role: 'user', content: 'Say hi' }],
        max_tokens: 10,
      }),
    })
  );

  const responses = await Promise.all(promises);
  const statuses = responses.map(r => r.status);

  // At least one should be rate limited
  expect(statuses).toContain(429);
});
```

## Response Headers

| Header | Description | Example |
|--------|-------------|---------|
| `X-RateLimit-Limit` | Max requests per window | `10` |
| `X-RateLimit-Remaining` | Requests left in window | `9` |
| `X-RateLimit-Reset` | Unix timestamp when limit resets | `1705612800` |

## Rate Limit Tiers

| Tier | Requests/Minute | Use Case |
|------|-----------------|----------|
| Free | 10 | Development, testing |
| Pro | 60 | Production apps |
| Enterprise | 1000+ | High-volume apps |
| Test | 1000 | Integration tests |

## Error Response

### 429 Too Many Requests

```json
{
  "error": {
    "code": "rate_limit_exceeded",
    "message": "Rate limit exceeded. Please retry after 60 seconds.",
    "type": "rate_limit_error",
    "retry_after": 60
  }
}
```

Response also includes:
```
Retry-After: 60
X-RateLimit-Limit: 10
X-RateLimit-Remaining: 0
X-RateLimit-Reset: 1705612860
```

## Rate Limit Algorithm

The API uses a sliding window algorithm:

```
1. Request received
   └─> Get user's rate limit tier

2. Check window
   └─> Count requests in last 60 seconds

3. Evaluate
   └─> If count < limit: Allow request
   └─> If count >= limit: Return 429

4. Track request
   └─> Log timestamp for future checks
```

## Handling Rate Limits

### Retry with Backoff

```typescript
async function callWithRetry(request: () => Promise<Response>) {
  const maxRetries = 3;
  let retries = 0;

  while (retries < maxRetries) {
    const response = await request();

    if (response.status !== 429) {
      return response;
    }

    const retryAfter = parseInt(
      response.headers.get('Retry-After') || '60'
    );
    await new Promise(resolve =>
      setTimeout(resolve, retryAfter * 1000)
    );
    retries++;
  }

  throw new Error('Max retries exceeded');
}
```

### Check Headers Proactively

```typescript
const response = await fetch(/* ... */);

const remaining = parseInt(
  response.headers.get('X-RateLimit-Remaining') || '0'
);

if (remaining < 2) {
  console.log('Approaching rate limit, slowing down...');
  await new Promise(resolve => setTimeout(resolve, 5000));
}
```

## Best Practices

1. **Respect Retry-After** - Don't hammer the API
2. **Implement backoff** - Exponential backoff for retries
3. **Monitor remaining** - Track headers proactively
4. **Batch requests** - Combine when possible
5. **Use webhooks** - For async workflows
