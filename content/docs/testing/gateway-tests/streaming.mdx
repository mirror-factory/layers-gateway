---
title: Streaming Tests
description: 2 tests for SSE streaming responses
---

# Streaming Tests

Streaming tests verify that models can stream responses using Server-Sent Events (SSE) format.

## Test Summary

| Test | Model | Description |
|------|-------|-------------|
| Claude Streaming | claude-haiku-4.5 | Stream text chunks |
| GPT-4o Streaming | gpt-4o-mini | Stream text chunks |

## Running Tests

```bash
cd packages/@layers/models
AI_GATEWAY_API_KEY=vck_xxx bun test gateway -t "stream"
```

## Test Implementation

### Claude Streaming Test

```typescript
it('should stream responses with Claude', async () => {
  const { textStream } = await streamText({
    model: gateway('anthropic/claude-haiku-4.5'),
    prompt: 'Count from 1 to 5.',
    maxTokens: 50,
  });

  const chunks: string[] = [];
  for await (const chunk of textStream) {
    chunks.push(chunk);
  }

  expect(chunks.length).toBeGreaterThan(1);
  const fullText = chunks.join('');
  expect(fullText).toContain('1');
  expect(fullText).toContain('5');
});
```

### GPT-4o Streaming Test

```typescript
it('should stream responses with GPT-4o', async () => {
  const { textStream } = await streamText({
    model: gateway('openai/gpt-4o-mini'),
    prompt: 'Count from 1 to 5.',
    maxTokens: 50,
  });

  const chunks: string[] = [];
  for await (const chunk of textStream) {
    chunks.push(chunk);
  }

  expect(chunks.length).toBeGreaterThan(1);
});
```

## Stream Response Structure

Streaming returns an async iterable of text chunks:

```typescript
import { streamText } from 'ai';

const { textStream, fullStream } = await streamText({
  model: gateway('anthropic/claude-haiku-4.5'),
  prompt: 'Hello!',
});

// Simple text chunks
for await (const chunk of textStream) {
  process.stdout.write(chunk);
}

// Full stream with metadata
for await (const part of fullStream) {
  switch (part.type) {
    case 'text-delta':
      console.log('Text:', part.textDelta);
      break;
    case 'finish':
      console.log('Finish reason:', part.finishReason);
      console.log('Usage:', part.usage);
      break;
  }
}
```

## SSE Format

The underlying transport uses Server-Sent Events:

```
data: {"type":"text-delta","textDelta":"Hello"}

data: {"type":"text-delta","textDelta":" world"}

data: {"type":"finish","finishReason":"stop"}

data: [DONE]
```

## Supported Models

| Model | Streaming |
|-------|-----------|
| anthropic/claude-* | Yes |
| openai/gpt-* | Yes |
| google/gemini-* | Yes |
| perplexity/sonar | Yes |
| morph/morph-* | Yes |

All language models support streaming.

## Use Cases

### Real-time UI Updates

```typescript
const { textStream } = await streamText({
  model: gateway('anthropic/claude-haiku-4.5'),
  prompt: userInput,
});

for await (const chunk of textStream) {
  // Update UI immediately as chunks arrive
  appendToChat(chunk);
}
```

### Progress Indicators

```typescript
let tokenCount = 0;
for await (const part of fullStream) {
  if (part.type === 'text-delta') {
    tokenCount++;
    updateProgress(`Generating... ${tokenCount} tokens`);
  }
}
```

## Error Handling

```typescript
try {
  for await (const chunk of textStream) {
    process.stdout.write(chunk);
  }
} catch (error) {
  if (error.name === 'AbortError') {
    console.log('Stream aborted');
  } else {
    console.error('Stream error:', error);
  }
}
```
